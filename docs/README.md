# Prompt Templating for Large Language Models Querying

`instruct` is a Python library for developers to carefully write rich prompts, test them and iterate faster on prompt <> model fit.
It works best with the `vscode-instruct` extension

> `We don't know what we don't know.` ... GitHub Copilot suggested to complete with: `but we can ask the right questions to find out.`

The goal of this library is to provide a simple way to generate prompts for querying LLMs.


## Why?

We want to give developers the tools to explore the capabilities of open-source LLMs from the perspective of querying them with well-crafted instructions, before considering fine-tuning.

We've seen performance improvements using the same model (ReACT, CoT, ToT, ...) from different prompting techniques and we want to build a tool that's useful for developers to explore these techniques even further.

Common frameworks like LangChain and LlamaIndex are great for building applications on top of LLMs, but they hide the richness of prompting strategies. This is where we want to focus.

Here's the big motivation: make open-source models production-ready for complex LLM-based applications without fine-tuning.

Gigantic models like GPT-4 generalize very well. Too well, maybe. They make developers lazy. It's too easy prompting badly a model that performs well, rather than thinking on smart approaches to query less RLHFed LLMs.

And that's a fact: less powerful models, i.e. open-weights / open-source models, tend to react less well to low-quality prompts and require more specific instructions.

If we want to query open-source LLMs and build applications out of them, we need a toolbox for developers to iterate, find, and evaluate the right instructions.

That's where Prompt Templating comes in.


## Use cases

- Get out of gigantic models – like GPT4 – dependency: use large open-source models with model-specific instructions
- Implement small models with a model-specific instruction-based strategy
- Prepare datasets for fine-tuning with model-specific instructions

## Principles

- Treat LLMs as prompt instructions interpreters
- one single place for the logic of each "instruction" whatever the model
- each model respond differently to prompts
- model-specific instructions generated by templating
- templating is to prompt what variables are to code
- model selection at runtime has to be developer-driven and self-ported

## Credit & Inspiration

`Prompting` is a new concept that has been introduced as a way to query Large Language Models.

In fact "prompting" was coined after the first release of "instruct" versions of GPT models.

With this "instruction-based" fine-tuning strategy, the LLM is more prone to answer queries that looks like instructions, thus the term "prompting".


This package is taking inspiration from the Mojodex Prompt Template library, which has been designed and built as a way to handle the complex prompting strategy.
This effort is a way to make this tool independent, simple and easy to use for developers to explore LLMs querying.

## TODO


- fix --model flag in run command
- create a getting started and tutorial
- create a README à la https://github.com/darold/pgbadger/blob/master/doc/pgBadger.pod
- save each calls in ./instruct/dataset pair query<>answer + instruct model used [optional feedback, use case] for further use